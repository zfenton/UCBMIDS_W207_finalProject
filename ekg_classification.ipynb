{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = \"ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3/\"\n",
    "sampling_rate = 100\n",
    "\n",
    "Y = pd.read_csv(path + \"ptbxl_database.csv\", index_col=\"ecg_id\")\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "agg_df = pd.read_csv(path + \"scp_statements.csv\", index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "Y['diagnostic_superclass'] = Y['diagnostic_superclass'].apply(lambda x: x[0] if len(x) > 0 else 'NORM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.119, -0.055,  0.064, ..., -0.026, -0.039, -0.079],\n",
       "       [-0.116, -0.051,  0.065, ..., -0.031, -0.034, -0.074],\n",
       "       [-0.12 , -0.044,  0.076, ..., -0.028, -0.029, -0.069],\n",
       "       ...,\n",
       "       [ 0.069,  0.   , -0.069, ...,  0.024, -0.041, -0.058],\n",
       "       [ 0.086,  0.004, -0.081, ...,  0.242, -0.046, -0.098],\n",
       "       [ 0.022, -0.031, -0.054, ...,  0.143, -0.035, -0.12 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] # First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CD', 'HYP', 'MI', 'NORM', 'STTC'], dtype=object),\n",
       " array([3422,  535, 2715, 9925, 5202]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Y['diagnostic_superclass'].to_numpy()\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "classes, counts # Don't end up with same counts each time - fix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CD' 'HYP' 'MI' 'NORM' 'STTC'] [2738  436 2201 7907 4157]\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_classes, train_counts = np.unique(y_train, return_counts=True)\n",
    "print(train_classes, train_counts)\n",
    "smallest_class_count = min(train_counts)\n",
    "print(smallest_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_subset(ekg_class):\n",
    "    y_train_class_indices = np.where(y_train == ekg_class)[0]\n",
    "    y_train_class_subset_indices = np.random.choice(\n",
    "        y_train_class_indices,\n",
    "        size=smallest_class_count,\n",
    "        replace=False\n",
    "    )\n",
    "    X_train_class_subset = X_train[y_train_class_subset_indices]\n",
    "    y_train_class_subset = np.array([ekg_class] * smallest_class_count)\n",
    "    return X_train_class_subset, y_train_class_subset\n",
    "\n",
    "X_train_cd, y_train_cd = get_class_subset('CD')\n",
    "X_train_hyp, y_train_hyp = get_class_subset('HYP')\n",
    "X_train_mi, y_train_mi = get_class_subset('MI')\n",
    "X_train_norm, y_train_norm = get_class_subset('NORM')\n",
    "X_train_sttc, y_train_sttc = get_class_subset('STTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436, 1000, 12)\n",
      "(436, 1000, 12)\n",
      "(436, 1000, 12)\n",
      "(436, 1000, 12)\n",
      "(436, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cd.shape)\n",
    "print(X_train_hyp.shape)\n",
    "print(X_train_mi.shape)\n",
    "print(X_train_norm.shape)\n",
    "print(X_train_sttc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180, 1000, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate((X_train_cd, X_train_hyp, X_train_mi, X_train_norm, X_train_sttc))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436,)\n",
      "(436,)\n",
      "(436,)\n",
      "(436,)\n",
      "(436,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_cd.shape)\n",
    "print(y_train_hyp.shape)\n",
    "print(y_train_mi.shape)\n",
    "print(y_train_norm.shape)\n",
    "print(y_train_sttc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.concatenate((y_train_cd, y_train_hyp, y_train_mi, y_train_norm, y_train_sttc))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1744, 1000, 12)\n",
      "Training labels shape: (1744,) \n",
      "\n",
      "Validation data shape: (436, 1000, 12)\n",
      "Validation labels shape: (436,) \n",
      "\n",
      "Test data shape: (4360, 1000, 12)\n",
      "Test labels shape: (4360,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape:', X_train.shape)\n",
    "print('Training labels shape:', y_train.shape, '\\n')\n",
    "print('Validation data shape:', X_val.shape)\n",
    "print('Validation labels shape:', y_val.shape, '\\n')\n",
    "print('Test data shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data_mean = data.mean()\n",
    "    data_sd = data.std()\n",
    "    return (data - data_mean) / data_sd\n",
    "\n",
    "X_train_norm = normalize(X_train)\n",
    "X_val_norm = normalize(X_val)\n",
    "X_test_norm = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.19438073394495411\n",
      "Validation accuracy: 0.2018348623853211\n",
      "Test accuracy: 0.1926605504587156\n"
     ]
    }
   ],
   "source": [
    "def random_classification(training_data):\n",
    "    return [np.random.choice(classes) for _ in training_data]\n",
    "\n",
    "predictions_train = random_classification(X_train)\n",
    "accuracy_train = accuracy_score(y_train, predictions_train)\n",
    "print('Training accuracy:', accuracy_train)\n",
    "\n",
    "predictions_val = random_classification(X_val)\n",
    "accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "print('Validation accuracy:', accuracy_val)\n",
    "\n",
    "predictions_test = random_classification(X_test)\n",
    "accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "print('Test accuracy:', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.20814220183486237\n",
      "Validation accuracy: 0.16743119266055045\n",
      "Test accuracy: 0.4628440366972477\n"
     ]
    }
   ],
   "source": [
    "def always_classify_normal(training_data):\n",
    "    return ['NORM'] * len(training_data)\n",
    "\n",
    "predictions_train = always_classify_normal(X_train)\n",
    "accuracy_train = accuracy_score(y_train, predictions_train)\n",
    "print('Training accuracy:', accuracy_train)\n",
    "\n",
    "predictions_val = always_classify_normal(X_val)\n",
    "accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "print('Validation accuracy:', accuracy_val)\n",
    "\n",
    "predictions_test = always_classify_normal(X_test)\n",
    "accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "print('Test accuracy:', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1744, 12000)\n",
      "(436, 12000)\n",
      "(4360, 12000)\n"
     ]
    }
   ],
   "source": [
    "X_train_flattened = np.array([ekg.flatten() for ekg in X_train])\n",
    "print(X_train_flattened.shape)\n",
    "\n",
    "X_val_flattened = np.array([ekg.flatten() for ekg in X_val])\n",
    "print(X_val_flattened.shape)\n",
    "\n",
    "X_test_flattened = np.array([ekg.flatten() for ekg in X_test])\n",
    "print(X_test_flattened.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9501146788990825\n",
      "Validation accuracy: 0.26146788990825687\n",
      "Test accuracy: 0.25229357798165136\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth = 12).fit(X_train_flattened, y_train) \n",
    "\n",
    "predictions_train = dt_model.predict(X_train_flattened)\n",
    "accuracy_train = accuracy_score(y_train, predictions_train)\n",
    "print('Training accuracy:', accuracy_train)\n",
    "\n",
    "predictions_val = dt_model.predict(X_val_flattened)\n",
    "accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "print('Validation accuracy:', accuracy_val)\n",
    "\n",
    "predictions_test = dt_model.predict(X_test_flattened)\n",
    "accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "print('Test accuracy:', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.19495412844036697\n",
      "Test accuracy: 0.2353211009174312\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel = 'linear', C = 1).fit(X_train_flattened, y_train) \n",
    "\n",
    "predictions_train = svm_model.predict(X_train_flattened)\n",
    "accuracy_train = accuracy_score(y_train, predictions_train)\n",
    "print('Training accuracy:', accuracy_train)\n",
    "\n",
    "predictions_val = svm_model.predict(X_val_flattened)\n",
    "accuracy_val = accuracy_score(y_val, predictions_val)\n",
    "print('Validation accuracy:', accuracy_val)\n",
    "\n",
    "predictions_test = svm_model.predict(X_test_flattened)\n",
    "accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "print('Test accuracy:', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_val = mlb.transform(y_val)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 3s 37ms/step - loss: 0.6861 - accuracy: 0.0430 - val_loss: 0.6635 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.6402 - accuracy: 0.0384 - val_loss: 0.5997 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.6057 - accuracy: 0.0619 - val_loss: 0.5608 - val_accuracy: 0.4220\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 178s 3s/step - loss: 0.5744 - accuracy: 0.1439 - val_loss: 0.5325 - val_accuracy: 0.4220\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 2s 38ms/step - loss: 0.5604 - accuracy: 0.2196 - val_loss: 0.5175 - val_accuracy: 0.4427\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.5503 - accuracy: 0.3005 - val_loss: 0.5110 - val_accuracy: 0.4679\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 2s 35ms/step - loss: 0.5397 - accuracy: 0.3469 - val_loss: 0.5211 - val_accuracy: 0.3761\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.5292 - accuracy: 0.4100 - val_loss: 0.5211 - val_accuracy: 0.3073\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.5184 - accuracy: 0.4249 - val_loss: 0.4962 - val_accuracy: 0.3807\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.5032 - accuracy: 0.4444 - val_loss: 0.4828 - val_accuracy: 0.4014\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.4907 - accuracy: 0.4725 - val_loss: 0.4713 - val_accuracy: 0.4450\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - 2s 33ms/step - loss: 0.4751 - accuracy: 0.4880 - val_loss: 0.4722 - val_accuracy: 0.4312\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4693 - accuracy: 0.4857 - val_loss: 0.4808 - val_accuracy: 0.3968\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4524 - accuracy: 0.5029 - val_loss: 0.4961 - val_accuracy: 0.3876\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4427 - accuracy: 0.5155 - val_loss: 0.4962 - val_accuracy: 0.3830\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4286 - accuracy: 0.5390 - val_loss: 0.4946 - val_accuracy: 0.3784\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4175 - accuracy: 0.5487 - val_loss: 0.4867 - val_accuracy: 0.4083\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.4022 - accuracy: 0.5533 - val_loss: 0.4925 - val_accuracy: 0.4518\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - 2s 34ms/step - loss: 0.3908 - accuracy: 0.5453 - val_loss: 0.5044 - val_accuracy: 0.4243\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - 2s 36ms/step - loss: 0.3848 - accuracy: 0.5327 - val_loss: 0.5351 - val_accuracy: 0.4243\n",
      "137/137 - 1s - loss: 0.5541 - accuracy: 0.6679 - 1s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6678898930549622"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(64, 3, activation='relu', input_shape=(1000, 12)))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(256, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
